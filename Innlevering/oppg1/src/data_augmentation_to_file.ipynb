{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_ROOT = '../../data/images/NGD_HACK'\n",
    "\n",
    "AUG_DATA_ROOT = '../../data/aug_data'\n",
    "\n",
    "# Train/Test split ratio\n",
    "TRAIN_SPLIT = 0.8  # 80% train, 20% test\n",
    "\n",
    "# We’ll do some typical augmentations: rotation, brightness, flips, etc.\n",
    "# You can tweak these depending on your scenario.\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    fill_mode='nearest'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------------------\n",
    "# FIND ALL CLASSES AND IMAGES\n",
    "# ---------------------------------------\n",
    "class_to_images = {}  # { \"4011\": [list_of_image_paths], ... }\n",
    "\n",
    "for class_name in os.listdir(RAW_DATA_ROOT):\n",
    "    class_path = os.path.join(RAW_DATA_ROOT, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue  # skip non-directory files\n",
    "    # Collect all image files in this folder\n",
    "    all_files = os.listdir(class_path)\n",
    "    image_files = [\n",
    "        f for f in all_files\n",
    "        if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "    ]\n",
    "    # Store absolute paths\n",
    "    image_paths = [os.path.join(class_path, img) for img in image_files]\n",
    "    class_to_images[class_name] = image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class '4011' has 234 images.\n",
      "Class '4015' has 484 images.\n",
      "Class '4088' has 350 images.\n",
      "Class '4196' has 474 images.\n",
      "Class '7020097009819' has 362 images.\n",
      "Class '7020097026113' has 122 images.\n",
      "Class '7023026089401' has 198 images.\n",
      "Class '7035620058776' has 52 images.\n",
      "Class '7037203626563' has 94 images.\n",
      "Class '7037206100022' has 324 images.\n",
      "Class '7038010009457' has 140 images.\n",
      "Class '7038010013966' has 322 images.\n",
      "Class '7038010021145' has 140 images.\n",
      "Class '7038010054488' has 240 images.\n",
      "Class '7038010068980' has 326 images.\n",
      "Class '7039610000318' has 232 images.\n",
      "Class '7040513000022' has 276 images.\n",
      "Class '7040513001753' has 110 images.\n",
      "Class '7040913336684' has 140 images.\n",
      "Class '7044610874661' has 576 images.\n",
      "Class '7048840205868' has 136 images.\n",
      "Class '7071688004713' has 102 images.\n",
      "Class '7622210410337' has 148 images.\n",
      "Class '90433917' has 186 images.\n",
      "Class '90433924' has 270 images.\n",
      "Class '94011' has 450 images.\n",
      "\n",
      "Max number of images in any class is 576\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------\n",
    "# DETERMINE CLASS DISTRIBUTION & TARGET\n",
    "# ---------------------------------------\n",
    "class_sizes = {cls: len(paths) for cls, paths in class_to_images.items() if len(paths) > 0}\n",
    "for c, count in class_sizes.items():\n",
    "    print(f\"Class '{c}' has {count} images.\")\n",
    "\n",
    "max_count = max(class_sizes.values()) if class_sizes else 0\n",
    "print(f\"\\nMax number of images in any class is {max_count}\")\n",
    "\n",
    "# (Optionally, if you want a user-defined target that’s different from max_count, you could override it)\n",
    "# Example: TARGET_IMAGES_PER_CLASS = 2000\n",
    "# But for now, we’ll use:\n",
    "TARGET_IMAGES_PER_CLASS = max_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/aug_data/train/<class_name>  and data/aug_data/test/<class_name>\n",
    "for split in ['train', 'test']:\n",
    "    split_dir = os.path.join(AUG_DATA_ROOT, split)\n",
    "    os.makedirs(split_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_class_images(class_name, image_paths, target_count):\n",
    "    \"\"\"\n",
    "    Takes a list of raw image paths for one class,\n",
    "    splits them into train/test, augments the train set up to target_count,\n",
    "    and saves them under data/aug_data/train/class_name and data/aug_data/test/class_name.\n",
    "    \"\"\"\n",
    "    random.shuffle(image_paths)\n",
    "    n_images = len(image_paths)\n",
    "    if n_images == 0:\n",
    "        return\n",
    "\n",
    "    # Determine train/test sizes\n",
    "    train_size = int(n_images * TRAIN_SPLIT)\n",
    "    train_paths = image_paths[:train_size]\n",
    "    test_paths = image_paths[train_size:]\n",
    "\n",
    "    # Create subdirs\n",
    "    train_out_dir = os.path.join(AUG_DATA_ROOT, 'train', class_name)\n",
    "    test_out_dir = os.path.join(AUG_DATA_ROOT, 'test', class_name)\n",
    "    os.makedirs(train_out_dir, exist_ok=True)\n",
    "    os.makedirs(test_out_dir, exist_ok=True)\n",
    "\n",
    "    # Copy test images as-is (no augmentation)\n",
    "    for i, test_img_path in enumerate(test_paths):\n",
    "        # We keep the original file name or rename systematically\n",
    "        filename = os.path.basename(test_img_path)\n",
    "        out_path = os.path.join(test_out_dir, filename)\n",
    "        shutil.copy2(test_img_path, out_path)\n",
    "\n",
    "    # For the train set, we want to “oversample” if needed, so total train images = target_count\n",
    "    # If the class already has enough images to meet or exceed target_count, we can either:\n",
    "    #   - do no augmentation\n",
    "    #   - or still do some augmentation for variety but limit total.\n",
    "    #\n",
    "    # For demonstration, we’ll do augmentation in any case. \n",
    "    # But if you want to keep original images + just generate new to meet target_count, adapt logic.\n",
    "    \n",
    "    # Step 1: Copy each original train image into train folder\n",
    "    for i, train_img_path in enumerate(train_paths):\n",
    "        filename = os.path.basename(train_img_path)\n",
    "        out_path = os.path.join(train_out_dir, filename)\n",
    "        shutil.copy2(train_img_path, out_path)\n",
    "\n",
    "    current_count = len(train_paths)\n",
    "    # Step 2: Use Keras ImageDataGenerator to create more images\n",
    "    # We'll pick from the original train images randomly to generate new ones until we reach target_count\n",
    "    print(f\"Augmenting {class_name} from {current_count} up to {target_count} images in train set...\")\n",
    "    \n",
    "    if current_count < target_count:\n",
    "        needed = target_count - current_count\n",
    "        # We'll do a simple approach: cycle through train images until we generate 'needed' augmented samples\n",
    "        # For large expansions, you may want a more advanced approach or a direct flow_from_directory pipeline\n",
    "        gen_count = 0\n",
    "        while gen_count < needed:\n",
    "            # pick a random train image\n",
    "            source_img_path = random.choice(train_paths)\n",
    "            # open it, augment 1 sample\n",
    "            img = load_img(source_img_path)\n",
    "            x = img_to_array(img)  # shape: (h, w, 3)\n",
    "            x = np.expand_dims(x, axis=0)  # shape: (1, h, w, 3)\n",
    "\n",
    "            # datagen.flow yields batches of augmented images\n",
    "            batch = next(datagen.flow(x, batch_size=1))\n",
    "            augmented_img = batch[0].astype('uint8')  # shape: (h, w, 3)\n",
    "\n",
    "            # save to disk\n",
    "            aug_filename = f\"aug_{class_name}_{gen_count}.jpg\"\n",
    "            aug_out_path = os.path.join(train_out_dir, aug_filename)\n",
    "            cv2.imwrite(aug_out_path, cv2.cvtColor(augmented_img, cv2.COLOR_RGB2BGR))\n",
    "            gen_count += 1\n",
    "    else:\n",
    "        print(f\"No augmentation needed for {class_name} (already has >= target_count)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes:   0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting 4011 from 187 up to 576 images in train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes:   4%|▍         | 1/26 [00:20<08:28, 20.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting 4015 from 387 up to 576 images in train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes:   8%|▊         | 2/26 [00:31<05:55, 14.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting 4088 from 280 up to 576 images in train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes:  12%|█▏        | 3/26 [00:46<05:49, 15.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting 4196 from 379 up to 576 images in train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes:  15%|█▌        | 4/26 [00:57<04:57, 13.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting 7020097009819 from 289 up to 576 images in train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes:  19%|█▉        | 5/26 [01:12<04:54, 14.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting 7020097026113 from 97 up to 576 images in train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes:  23%|██▎       | 6/26 [01:36<05:48, 17.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting 7023026089401 from 158 up to 576 images in train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes:  27%|██▋       | 7/26 [01:58<05:56, 18.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting 7035620058776 from 41 up to 576 images in train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes:  31%|███       | 8/26 [02:23<06:16, 20.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting 7037203626563 from 75 up to 576 images in train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes:  35%|███▍      | 9/26 [02:49<06:20, 22.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting 7037206100022 from 259 up to 576 images in train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes:  38%|███▊      | 10/26 [03:06<05:34, 20.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting 7038010009457 from 112 up to 576 images in train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes:  42%|████▏     | 11/26 [03:30<05:23, 21.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting 7038010013966 from 257 up to 576 images in train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes:  46%|████▌     | 12/26 [03:47<04:44, 20.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting 7038010021145 from 112 up to 576 images in train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes:  50%|█████     | 13/26 [04:10<04:32, 21.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting 7038010054488 from 192 up to 576 images in train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes:  54%|█████▍    | 14/26 [04:29<04:05, 20.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting 7038010068980 from 260 up to 576 images in train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes:  58%|█████▊    | 15/26 [04:46<03:33, 19.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting 7039610000318 from 185 up to 576 images in train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes:  62%|██████▏   | 16/26 [05:07<03:18, 19.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting 7040513000022 from 220 up to 576 images in train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes:  65%|██████▌   | 17/26 [05:26<02:56, 19.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting 7040513001753 from 88 up to 576 images in train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes:  69%|██████▉   | 18/26 [05:51<02:49, 21.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting 7040913336684 from 112 up to 576 images in train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes:  73%|███████▎  | 19/26 [06:13<02:30, 21.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting 7044610874661 from 460 up to 576 images in train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes:  77%|███████▋  | 20/26 [06:20<01:42, 17.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting 7048840205868 from 108 up to 576 images in train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes:  81%|████████  | 21/26 [06:42<01:33, 18.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting 7071688004713 from 81 up to 576 images in train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes:  85%|████████▍ | 22/26 [07:06<01:20, 20.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting 7622210410337 from 118 up to 576 images in train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes:  88%|████████▊ | 23/26 [07:28<01:02, 20.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting 90433917 from 148 up to 576 images in train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes:  92%|█████████▏| 24/26 [07:50<00:42, 21.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting 90433924 from 216 up to 576 images in train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes:  96%|█████████▌| 25/26 [08:07<00:20, 20.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting 94011 from 360 up to 576 images in train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes: 100%|██████████| 26/26 [08:19<00:00, 19.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data augmentation complete!\n",
      "Augmented data directory: ../../data/aug_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------------------------------------\n",
    "# RUN AUGMENTATION FOR EACH CLASS\n",
    "# ---------------------------------------\n",
    "\n",
    "for class_name, image_paths in tqdm(class_to_images.items(), desc=\"Classes\"):\n",
    "    if len(image_paths) == 0:\n",
    "        continue\n",
    "    augment_class_images(class_name, image_paths, TARGET_IMAGES_PER_CLASS)\n",
    "\n",
    "print(\"\\nData augmentation complete!\")\n",
    "print(f\"Augmented data directory: {AUG_DATA_ROOT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "#  SPLIT INTO TRAIN/TEST FOLDERS\n",
    "# ---------------------------------------\n",
    "# import os\n",
    "# import shutil\n",
    "# import random\n",
    "\n",
    "# SOURCE_DIR = '../../data/images/NGD_HACK'\n",
    "# TRAIN_DIR = '../../data/train'\n",
    "# TEST_DIR = '../../data/test'\n",
    "# SPLIT_RATIO = 0.8  # 80% train, 20% test\n",
    "\n",
    "# os.makedirs(TRAIN_DIR, exist_ok=True)\n",
    "# os.makedirs(TEST_DIR, exist_ok=True)\n",
    "\n",
    "# for class_name in os.listdir(SOURCE_DIR):\n",
    "#     class_path = os.path.join(SOURCE_DIR, class_name)\n",
    "#     if not os.path.isdir(class_path):\n",
    "#         continue\n",
    "    \n",
    "#     # Gather all image files\n",
    "#     all_files = [f for f in os.listdir(class_path) \n",
    "#                  if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "#     if len(all_files) == 0:\n",
    "#         continue\n",
    "    \n",
    "#     # Shuffle for randomization\n",
    "#     random.shuffle(all_files)\n",
    "#     split_index = int(len(all_files) * SPLIT_RATIO)\n",
    "    \n",
    "#     train_files = all_files[:split_index]\n",
    "#     test_files = all_files[split_index:]\n",
    "    \n",
    "#     # Make sure class subfolders exist in train/test\n",
    "#     train_class_dir = os.path.join(TRAIN_DIR, class_name)\n",
    "#     test_class_dir = os.path.join(TEST_DIR, class_name)\n",
    "#     os.makedirs(train_class_dir, exist_ok=True)\n",
    "#     os.makedirs(test_class_dir, exist_ok=True)\n",
    "    \n",
    "#     # Copy images into train\n",
    "#     for file_name in train_files:\n",
    "#         src = os.path.join(class_path, file_name)\n",
    "#         dst = os.path.join(train_class_dir, file_name)\n",
    "#         shutil.copy2(src, dst)\n",
    "    \n",
    "#     # Copy images into test\n",
    "#     for file_name in test_files:\n",
    "#         src = os.path.join(class_path, file_name)\n",
    "#         dst = os.path.join(test_class_dir, file_name)\n",
    "#         shutil.copy2(src, dst)\n",
    "\n",
    "# print(\"Split complete! Train/Test folders created.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
