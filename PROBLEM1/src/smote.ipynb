{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Original train directory with subfolders (one per class)\n",
    "TRAIN_DIR = '../../data/train'\n",
    "\n",
    "# Directory where we'll put a combined dataset:\n",
    "#   - original images\n",
    "#   - plus newly generated SMOTE images\n",
    "TRAIN_COMBINED_DIR = '../../data/train_combined'\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "def ensure_dir_exists(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def offline_smote_images_per_class():\n",
    "    \"\"\"\n",
    "    For each class in TRAIN_DIR, load all images into memory (for that class),\n",
    "    apply SMOTE, and write new images to TRAIN_COMBINED_DIR alongside the originals.\n",
    "    \"\"\"\n",
    "    classes = sorted(os.listdir(TRAIN_DIR))\n",
    "    print(\"Classes found:\", classes)\n",
    "\n",
    "    for cls in classes:\n",
    "        class_path = os.path.join(TRAIN_DIR, cls)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        \n",
    "        # Destination directory for combined data\n",
    "        combined_class_path = os.path.join(TRAIN_COMBINED_DIR, cls)\n",
    "        ensure_dir_exists(combined_class_path)\n",
    "\n",
    "        # ---------------------------------------------------\n",
    "        # 1) Load images for this class\n",
    "        # ---------------------------------------------------\n",
    "        print(f\"\\n[CLASS: {cls}] Loading images...\")\n",
    "        X_list = []\n",
    "        img_paths = []\n",
    "        for img_name in os.listdir(class_path):\n",
    "            img_full_path = os.path.join(class_path, img_name)\n",
    "            img = cv2.imread(img_full_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            img = cv2.resize(img, IMG_SIZE)  # (224,224,3)\n",
    "            X_list.append(img.reshape(-1))  # flatten to (224*224*3,)\n",
    "            img_paths.append(img_full_path)\n",
    "\n",
    "        X_arr = np.array(X_list, dtype=np.uint8)\n",
    "        n_original = len(X_arr)\n",
    "        if n_original == 0:\n",
    "            print(f\"No images found for class {cls}, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Labels are all the same class here, so just use zeros\n",
    "        y_arr = np.zeros(n_original, dtype=np.uint8)\n",
    "\n",
    "        # ---------------------------------------------------\n",
    "        # 2) Copy original images to combined folder\n",
    "        #    (so the new directory has both original + SMOTE)\n",
    "        # ---------------------------------------------------\n",
    "        print(f\"Copying original images to {combined_class_path}...\")\n",
    "        for img_path in img_paths:\n",
    "            base_name = os.path.basename(img_path)\n",
    "            cv2.imwrite(os.path.join(combined_class_path, base_name), cv2.imread(img_path))\n",
    "\n",
    "        # ---------------------------------------------------\n",
    "        # 3) Apply SMOTE on this single class\n",
    "        #    This will generate more data for the minority class.\n",
    "        # ---------------------------------------------------\n",
    "        if n_original < 2:\n",
    "            print(f\"Class {cls} has <2 images, skipping SMOTE.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Applying SMOTE to class '{cls}' with {n_original} images...\")\n",
    "        smote = SMOTE(random_state=42, k_neighbors=1)  \n",
    "        # k_neighbors=1 can help if a class is extremely small, but can produce duplicates.\n",
    "\n",
    "        X_sm, y_sm = smote.fit_resample(X_arr, y_arr)\n",
    "        # X_sm now includes both original + new synthetic data\n",
    "\n",
    "        new_count = len(X_sm)\n",
    "        generated_count = new_count - n_original\n",
    "        if generated_count <= 0:\n",
    "            print(f\"No new images were generated for class {cls}.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Generated {generated_count} new images for class {cls}.\")\n",
    "\n",
    "        # ---------------------------------------------------\n",
    "        # 4) Write out ONLY the newly generated images\n",
    "        #    i.e. from index [n_original ... new_count-1]\n",
    "        # ---------------------------------------------------\n",
    "        for idx in range(n_original, new_count):\n",
    "            # Convert back to shape (224,224,3)\n",
    "            sm_img = X_sm[idx].reshape(IMG_SIZE[1], IMG_SIZE[0], 3)\n",
    "            # Must ensure data type is valid for saving\n",
    "            sm_img = sm_img.astype(np.uint8)\n",
    "\n",
    "            out_filename = f\"smote_{cls}_{idx}.jpg\"\n",
    "            out_path = os.path.join(combined_class_path, out_filename)\n",
    "            cv2.imwrite(out_path, sm_img)\n",
    "\n",
    "    print(\"\\nAll classes processed. New SMOTE images are in:\", TRAIN_COMBINED_DIR)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Run the offline function\n",
    "# ---------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    offline_smote_images_per_class()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
